{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "'''\r\n",
    "差分内容\r\n",
    "\r\n",
    "ベースライン作成\r\n",
    "時系列クロスバリデーション\r\n",
    "\r\n",
    "複数model保存・読み出し・予測→重み付き平均\r\n",
    "重み付き平均はデータ量が多いほど重みを付けたがもっと適切なものを探る\r\n",
    "\r\n",
    "PB score\r\n",
    "0.56260\r\n",
    "'''"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n差分内容\\n\\nベースライン作成\\n時系列クロスバリデーション\\n\\n複数model保存・読み出し・予測→重み付き平均\\n重み付き平均はデータ量が多いほど重みを付けたがもっと適切なものを探る\\n\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# main module\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import pandas_profiling as pdp\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "import lightgbm as lgb\r\n",
    "\r\n",
    "from sklearn.metrics import log_loss\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "\r\n",
    "import datetime\r\n",
    "import gc\r\n",
    "import logging\r\n",
    "import pickle\r\n",
    "from pickle import load\r\n",
    "import sys, os\r\n",
    "\r\n",
    "# -------------------------------------独自モジュール-------------------------------------\r\n",
    "sys.path.append('../src/') #モジュールが入っているディレクトリのパスを指定\r\n",
    "import eda\r\n",
    "import maprepro as mpre\r\n",
    "import maprepro2 as mpre2\r\n",
    "# import config\r\n",
    "# from utils import setup_logger, ModelFactory\r\n",
    "# -------------------------------------独自モジュール-------------------------------------"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "path = '../../input'\r\n",
    "sample = pd.read_csv(f'{path}/sample_submission.csv')\r\n",
    "store = pd.read_csv(f'{path}/store.csv')\r\n",
    "test = pd.read_csv(f'{path}/test.csv')\r\n",
    "train = pd.read_csv(f'{path}/train.csv')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\hayatotominaga\\anaconda3\\envs\\rake4\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# periodの作成\r\n",
    "# periodのセット\r\n",
    "# - dateを残したままやって最後date削除\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def mk_ymd(df):\r\n",
    "    df['year'] = df.Date.apply(lambda x: x.split('-')[0]).astype(np.int16)\r\n",
    "    df['month'] = df.Date.apply(lambda x: x.split('-')[1]).astype(np.int16)\r\n",
    "    df['day'] = df.Date.apply(lambda x: x.split('-')[2]).astype(np.int8)\r\n",
    "    df = df.sort_values('Date')\r\n",
    "    return df\r\n",
    "train = mk_ymd(train)\r\n",
    "test = mk_ymd(test)\r\n",
    "\r\n",
    "# 時系列データであり、時間に沿って変数periodを設定したとする\r\n",
    "def mk_period(df,testdata=False):\r\n",
    "    if testdata == False:\r\n",
    "        df['period'] = np.arange(0, len(df)) // (len(df) // 4)\r\n",
    "        df['period'] = np.clip(df['period'], 0, 3)\r\n",
    "        return df\r\n",
    "    else:\r\n",
    "        df['period'] = 4\r\n",
    "        return df\r\n",
    "\r\n",
    "\r\n",
    "train = mk_period(train)\r\n",
    "test = mk_period(test,testdata=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train['StateHoliday'] = train.StateHoliday.astype('category')\r\n",
    "test['StateHoliday'] = test.StateHoliday.astype('category')\r\n",
    "\r\n",
    "target = ['Sales']\r\n",
    "notuse = ['Id','Date','Open']\r\n",
    "use = ['Store','DayOfWeek','Open','Promo','StateHoliday','SchoolHoliday','year','month','day','period']\r\n",
    "categorical_features = ['StateHoliday']\r\n",
    "\r\n",
    "train_y = train[target]\r\n",
    "train_x = train[use]\r\n",
    "test_x = test[use]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import warnings\r\n",
    "warnings.simplefilter('ignore')\r\n",
    "train_x = eda.reduce_mem_usage(train_x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "start size(BEFORE): 56.27 Mb\n",
      "Mem. usage decreased to 19.40 Mb (AFTER:65.5% reduction)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "\r\n",
    "# --------------------------------------------------\r\n",
    "import maprepro2 as mpre2\r\n",
    "NOW,TMP_DIR = mpre2.mk_dir()\r\n",
    "gc.collect()\r\n",
    "# --------------------------------------------------\r\n",
    "\r\n",
    "va_period_list = [1, 2, 3]\r\n",
    "for va_period in va_period_list:\r\n",
    "    print('i ================================================================== ',va_period)\r\n",
    "    is_tr = train_x['period'] < va_period\r\n",
    "    is_va = train_x['period'] == va_period\r\n",
    "    tr_x, va_x = train_x[is_tr], train_x[is_va]\r\n",
    "    tr_y, va_y = train_y[is_tr], train_y[is_va]\r\n",
    "    \r\n",
    "    lgb_train = lgb.Dataset(tr_x, tr_y)\r\n",
    "    lgb_eval = lgb.Dataset(va_x, va_y)\r\n",
    "\r\n",
    "    # ハイパーパラメータの設定\r\n",
    "    params = {'objective': 'regression',\r\n",
    "                'seed': 71,\r\n",
    "                'verbose': 1,\r\n",
    "                'metrics': 'rmse',\r\n",
    "                'force_col_wise':'true' # メモリが足りないから\r\n",
    "                }\r\n",
    "    num_round = 100\r\n",
    "\r\n",
    "    # 学習の実行\r\n",
    "    # カテゴリ変数をパラメータで指定している\r\n",
    "    # バリデーションデータもモデルに渡し、学習の進行とともにスコアがどう変わるかモニタリングする\r\n",
    "    categorical_features = categorical_features\r\n",
    "    model = lgb.train(params, lgb_train, num_boost_round=num_round,\r\n",
    "                    categorical_feature=categorical_features,\r\n",
    "                    valid_names=['train', 'valid'], valid_sets=[lgb_train, lgb_eval],\r\n",
    "                    )\r\n",
    "\r\n",
    "\r\n",
    "    tmpfile = f'{TMP_DIR}/trained_model{va_period}.pkl'\r\n",
    "    pickle.dump(model, open(tmpfile, 'wb'))\r\n",
    "\r\n",
    "    # バリデーションデータでのスコアの確認\r\n",
    "    va_pred = model.predict(va_x); va_pred = va_pred.reshape(-1, 1)\r\n",
    "\r\n",
    "    # Open=0の日はすべてSalesが0で、0以外を予測することはありえないので0で更新(モデルは自然数を予測しているみたいだが、\r\n",
    "    # Open=0ならSales=0をモデルに教えられていないということ)\r\n",
    "    tmp =va_y['Sales']==0\r\n",
    "    va_pred[tmp]=0\r\n",
    "    va_pred=va_pred+1; va_y=va_y+1\r\n",
    "\r\n",
    "    # --------------------------------------------------\r\n",
    "    # score = mean_squared_error(va_y, va_pred)\r\n",
    "    RMSPE = np.sqrt(np.mean(((  (va_y-va_pred)/va_y)**2) )).values\r\n",
    "    RMSPE = RMSPE.astype(float)[0] # printのために単一の数値にしたかった\r\n",
    "    # score = log_loss(va_y, va_pred)\r\n",
    "    print('RMSPE RMSPE RMSPE RMSPE RMSPE RMSPE: {:.4f}'.format(RMSPE))\r\n",
    "    # --------------------------------------------------\r\n",
    "\r\n",
    "    del model # 学習済みモデルを削除\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "i ==================================================================  1\n",
      "[LightGBM] [Info] Total Bins 313\n",
      "[LightGBM] [Info] Number of data points in the train set: 254302, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 5576.839962\n",
      "[1]\ttrain's rmse: 3512.84\tvalid's rmse: 3644.08\n",
      "[2]\ttrain's rmse: 3335.43\tvalid's rmse: 3478\n",
      "[3]\ttrain's rmse: 3184.13\tvalid's rmse: 3335.7\n",
      "[4]\ttrain's rmse: 3055.07\tvalid's rmse: 3214.79\n",
      "[5]\ttrain's rmse: 2946.45\tvalid's rmse: 3114.04\n",
      "[6]\ttrain's rmse: 2855.12\tvalid's rmse: 3029.43\n",
      "[7]\ttrain's rmse: 2775.91\tvalid's rmse: 2954.98\n",
      "[8]\ttrain's rmse: 2710.06\tvalid's rmse: 2893.86\n",
      "[9]\ttrain's rmse: 2654.18\tvalid's rmse: 2840.49\n",
      "[10]\ttrain's rmse: 2608.38\tvalid's rmse: 2797.55\n",
      "[11]\ttrain's rmse: 2570.76\tvalid's rmse: 2760.34\n",
      "[12]\ttrain's rmse: 2536.69\tvalid's rmse: 2727.66\n",
      "[13]\ttrain's rmse: 2510.62\tvalid's rmse: 2701.75\n",
      "[14]\ttrain's rmse: 2489.38\tvalid's rmse: 2681.85\n",
      "[15]\ttrain's rmse: 2468.82\tvalid's rmse: 2661.58\n",
      "[16]\ttrain's rmse: 2451.46\tvalid's rmse: 2644.37\n",
      "[17]\ttrain's rmse: 2436.61\tvalid's rmse: 2628.76\n",
      "[18]\ttrain's rmse: 2423.19\tvalid's rmse: 2615.59\n",
      "[19]\ttrain's rmse: 2413.7\tvalid's rmse: 2606.17\n",
      "[20]\ttrain's rmse: 2403.32\tvalid's rmse: 2594.86\n",
      "[21]\ttrain's rmse: 2392.42\tvalid's rmse: 2584.5\n",
      "[22]\ttrain's rmse: 2386.8\tvalid's rmse: 2579.35\n",
      "[23]\ttrain's rmse: 2379.47\tvalid's rmse: 2572.08\n",
      "[24]\ttrain's rmse: 2369.35\tvalid's rmse: 2563.16\n",
      "[25]\ttrain's rmse: 2365.58\tvalid's rmse: 2559.18\n",
      "[26]\ttrain's rmse: 2359.66\tvalid's rmse: 2553.66\n",
      "[27]\ttrain's rmse: 2353.2\tvalid's rmse: 2547.93\n",
      "[28]\ttrain's rmse: 2348.59\tvalid's rmse: 2542.98\n",
      "[29]\ttrain's rmse: 2346.03\tvalid's rmse: 2541.4\n",
      "[30]\ttrain's rmse: 2338.21\tvalid's rmse: 2533.84\n",
      "[31]\ttrain's rmse: 2328.99\tvalid's rmse: 2525.44\n",
      "[32]\ttrain's rmse: 2322.17\tvalid's rmse: 2519.18\n",
      "[33]\ttrain's rmse: 2320.41\tvalid's rmse: 2516.87\n",
      "[34]\ttrain's rmse: 2312.34\tvalid's rmse: 2509.31\n",
      "[35]\ttrain's rmse: 2306.29\tvalid's rmse: 2503.57\n",
      "[36]\ttrain's rmse: 2304.56\tvalid's rmse: 2502.83\n",
      "[37]\ttrain's rmse: 2303.25\tvalid's rmse: 2501.77\n",
      "[38]\ttrain's rmse: 2296.53\tvalid's rmse: 2495.56\n",
      "[39]\ttrain's rmse: 2294.47\tvalid's rmse: 2494.37\n",
      "[40]\ttrain's rmse: 2293.32\tvalid's rmse: 2493.92\n",
      "[41]\ttrain's rmse: 2287.91\tvalid's rmse: 2489.1\n",
      "[42]\ttrain's rmse: 2286.86\tvalid's rmse: 2488.62\n",
      "[43]\ttrain's rmse: 2283.64\tvalid's rmse: 2485.64\n",
      "[44]\ttrain's rmse: 2282.64\tvalid's rmse: 2485.22\n",
      "[45]\ttrain's rmse: 2278.75\tvalid's rmse: 2481.87\n",
      "[46]\ttrain's rmse: 2277.64\tvalid's rmse: 2480.7\n",
      "[47]\ttrain's rmse: 2274.03\tvalid's rmse: 2477.59\n",
      "[48]\ttrain's rmse: 2271.13\tvalid's rmse: 2475.1\n",
      "[49]\ttrain's rmse: 2270.41\tvalid's rmse: 2474.31\n",
      "[50]\ttrain's rmse: 2267.92\tvalid's rmse: 2471.98\n",
      "[51]\ttrain's rmse: 2263.32\tvalid's rmse: 2468.01\n",
      "[52]\ttrain's rmse: 2262.29\tvalid's rmse: 2467.15\n",
      "[53]\ttrain's rmse: 2260.31\tvalid's rmse: 2465.47\n",
      "[54]\ttrain's rmse: 2259.54\tvalid's rmse: 2465.16\n",
      "[55]\ttrain's rmse: 2258.22\tvalid's rmse: 2464.03\n",
      "[56]\ttrain's rmse: 2256.02\tvalid's rmse: 2462.09\n",
      "[57]\ttrain's rmse: 2252.44\tvalid's rmse: 2459.16\n",
      "[58]\ttrain's rmse: 2250.96\tvalid's rmse: 2458.01\n",
      "[59]\ttrain's rmse: 2250.47\tvalid's rmse: 2457.62\n",
      "[60]\ttrain's rmse: 2249.27\tvalid's rmse: 2456.65\n",
      "[61]\ttrain's rmse: 2247.81\tvalid's rmse: 2455.27\n",
      "[62]\ttrain's rmse: 2247.18\tvalid's rmse: 2454.82\n",
      "[63]\ttrain's rmse: 2245.98\tvalid's rmse: 2453.75\n",
      "[64]\ttrain's rmse: 2244.5\tvalid's rmse: 2452.47\n",
      "[65]\ttrain's rmse: 2241.53\tvalid's rmse: 2449.8\n",
      "[66]\ttrain's rmse: 2240.99\tvalid's rmse: 2449.2\n",
      "[67]\ttrain's rmse: 2239.62\tvalid's rmse: 2448.25\n",
      "[68]\ttrain's rmse: 2238.84\tvalid's rmse: 2447.56\n",
      "[69]\ttrain's rmse: 2235.49\tvalid's rmse: 2444.72\n",
      "[70]\ttrain's rmse: 2233.77\tvalid's rmse: 2443.22\n",
      "[71]\ttrain's rmse: 2233.22\tvalid's rmse: 2442.89\n",
      "[72]\ttrain's rmse: 2232.51\tvalid's rmse: 2442.81\n",
      "[73]\ttrain's rmse: 2230.74\tvalid's rmse: 2441.32\n",
      "[74]\ttrain's rmse: 2230.2\tvalid's rmse: 2441.19\n",
      "[75]\ttrain's rmse: 2229.68\tvalid's rmse: 2440.91\n",
      "[76]\ttrain's rmse: 2228.75\tvalid's rmse: 2440.14\n",
      "[77]\ttrain's rmse: 2227.44\tvalid's rmse: 2438.96\n",
      "[78]\ttrain's rmse: 2224.8\tvalid's rmse: 2436.74\n",
      "[79]\ttrain's rmse: 2224.1\tvalid's rmse: 2436.16\n",
      "[80]\ttrain's rmse: 2223.36\tvalid's rmse: 2435.5\n",
      "[81]\ttrain's rmse: 2222.91\tvalid's rmse: 2435.13\n",
      "[82]\ttrain's rmse: 2222.42\tvalid's rmse: 2435.39\n",
      "[83]\ttrain's rmse: 2220.73\tvalid's rmse: 2433.98\n",
      "[84]\ttrain's rmse: 2218.33\tvalid's rmse: 2431.95\n",
      "[85]\ttrain's rmse: 2216.91\tvalid's rmse: 2430.82\n",
      "[86]\ttrain's rmse: 2216.51\tvalid's rmse: 2430.59\n",
      "[87]\ttrain's rmse: 2215.97\tvalid's rmse: 2430.17\n",
      "[88]\ttrain's rmse: 2215.61\tvalid's rmse: 2429.88\n",
      "[89]\ttrain's rmse: 2214.25\tvalid's rmse: 2428.66\n",
      "[90]\ttrain's rmse: 2212.27\tvalid's rmse: 2426.93\n",
      "[91]\ttrain's rmse: 2211.85\tvalid's rmse: 2426.95\n",
      "[92]\ttrain's rmse: 2211.5\tvalid's rmse: 2426.69\n",
      "[93]\ttrain's rmse: 2210.92\tvalid's rmse: 2426.22\n",
      "[94]\ttrain's rmse: 2210.59\tvalid's rmse: 2426.12\n",
      "[95]\ttrain's rmse: 2209.65\tvalid's rmse: 2425.37\n",
      "[96]\ttrain's rmse: 2208.23\tvalid's rmse: 2424.28\n",
      "[97]\ttrain's rmse: 2207.75\tvalid's rmse: 2423.84\n",
      "[98]\ttrain's rmse: 2207.46\tvalid's rmse: 2423.62\n",
      "[99]\ttrain's rmse: 2205.98\tvalid's rmse: 2422.38\n",
      "[100]\ttrain's rmse: 2204.76\tvalid's rmse: 2421.31\n",
      "RMSPE RMSPE RMSPE RMSPE RMSPE RMSPE: 0.4287\n",
      "i ==================================================================  2\n",
      "[LightGBM] [Info] Total Bins 324\n",
      "[LightGBM] [Info] Number of data points in the train set: 508604, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 5648.631594\n",
      "[1]\ttrain's rmse: 3566.56\tvalid's rmse: 3646.87\n",
      "[2]\ttrain's rmse: 3383.82\tvalid's rmse: 3463.86\n",
      "[3]\ttrain's rmse: 3227.83\tvalid's rmse: 3308.54\n",
      "[4]\ttrain's rmse: 3095.89\tvalid's rmse: 3172.55\n",
      "[5]\ttrain's rmse: 2983.21\tvalid's rmse: 3058.76\n",
      "[6]\ttrain's rmse: 2887.59\tvalid's rmse: 2961.78\n",
      "[7]\ttrain's rmse: 2807.7\tvalid's rmse: 2879.77\n",
      "[8]\ttrain's rmse: 2741.84\tvalid's rmse: 2813.15\n",
      "[9]\ttrain's rmse: 2685.6\tvalid's rmse: 2753.26\n",
      "[10]\ttrain's rmse: 2637.97\tvalid's rmse: 2703.82\n",
      "[11]\ttrain's rmse: 2599.45\tvalid's rmse: 2664.75\n",
      "[12]\ttrain's rmse: 2566.83\tvalid's rmse: 2629.7\n",
      "[13]\ttrain's rmse: 2538.82\tvalid's rmse: 2600.02\n",
      "[14]\ttrain's rmse: 2516.73\tvalid's rmse: 2576.79\n",
      "[15]\ttrain's rmse: 2497.04\tvalid's rmse: 2555.25\n",
      "[16]\ttrain's rmse: 2478.31\tvalid's rmse: 2533.81\n",
      "[17]\ttrain's rmse: 2463.22\tvalid's rmse: 2516.99\n",
      "[18]\ttrain's rmse: 2451.45\tvalid's rmse: 2504.37\n",
      "[19]\ttrain's rmse: 2439.79\tvalid's rmse: 2491.58\n",
      "[20]\ttrain's rmse: 2431.29\tvalid's rmse: 2482.61\n",
      "[21]\ttrain's rmse: 2421.98\tvalid's rmse: 2472.21\n",
      "[22]\ttrain's rmse: 2415.11\tvalid's rmse: 2464.42\n",
      "[23]\ttrain's rmse: 2407.26\tvalid's rmse: 2456.33\n",
      "[24]\ttrain's rmse: 2398.74\tvalid's rmse: 2446.25\n",
      "[25]\ttrain's rmse: 2394.3\tvalid's rmse: 2442.86\n",
      "[26]\ttrain's rmse: 2387.86\tvalid's rmse: 2435.87\n",
      "[27]\ttrain's rmse: 2384.21\tvalid's rmse: 2432.97\n",
      "[28]\ttrain's rmse: 2373.38\tvalid's rmse: 2421.69\n",
      "[29]\ttrain's rmse: 2370.37\tvalid's rmse: 2419.61\n",
      "[30]\ttrain's rmse: 2361.72\tvalid's rmse: 2410.41\n",
      "[31]\ttrain's rmse: 2357.85\tvalid's rmse: 2406.31\n",
      "[32]\ttrain's rmse: 2350.4\tvalid's rmse: 2399.86\n",
      "[33]\ttrain's rmse: 2348.21\tvalid's rmse: 2398.23\n",
      "[34]\ttrain's rmse: 2341.2\tvalid's rmse: 2390.79\n",
      "[35]\ttrain's rmse: 2338.64\tvalid's rmse: 2388.69\n",
      "[36]\ttrain's rmse: 2331.82\tvalid's rmse: 2381.46\n",
      "[37]\ttrain's rmse: 2325.79\tvalid's rmse: 2376.62\n",
      "[38]\ttrain's rmse: 2324.07\tvalid's rmse: 2375.66\n",
      "[39]\ttrain's rmse: 2322.54\tvalid's rmse: 2374.7\n",
      "[40]\ttrain's rmse: 2320.57\tvalid's rmse: 2372.71\n",
      "[41]\ttrain's rmse: 2319.29\tvalid's rmse: 2372.14\n",
      "[42]\ttrain's rmse: 2316.07\tvalid's rmse: 2368.95\n",
      "[43]\ttrain's rmse: 2314.86\tvalid's rmse: 2368.03\n",
      "[44]\ttrain's rmse: 2313.94\tvalid's rmse: 2367.63\n",
      "[45]\ttrain's rmse: 2310.82\tvalid's rmse: 2364.55\n",
      "[46]\ttrain's rmse: 2306.95\tvalid's rmse: 2361.68\n",
      "[47]\ttrain's rmse: 2305.52\tvalid's rmse: 2361.08\n",
      "[48]\ttrain's rmse: 2302.01\tvalid's rmse: 2357.51\n",
      "[49]\ttrain's rmse: 2299.6\tvalid's rmse: 2355.52\n",
      "[50]\ttrain's rmse: 2298.87\tvalid's rmse: 2355.46\n",
      "[51]\ttrain's rmse: 2295.58\tvalid's rmse: 2351.96\n",
      "[52]\ttrain's rmse: 2293.81\tvalid's rmse: 2350.6\n",
      "[53]\ttrain's rmse: 2292.85\tvalid's rmse: 2350.24\n",
      "[54]\ttrain's rmse: 2292.04\tvalid's rmse: 2350.63\n",
      "[55]\ttrain's rmse: 2289.29\tvalid's rmse: 2347.7\n",
      "[56]\ttrain's rmse: 2287.85\tvalid's rmse: 2346.21\n",
      "[57]\ttrain's rmse: 2285.68\tvalid's rmse: 2344.57\n",
      "[58]\ttrain's rmse: 2284.99\tvalid's rmse: 2344.25\n",
      "[59]\ttrain's rmse: 2283.72\tvalid's rmse: 2342.97\n",
      "[60]\ttrain's rmse: 2281.87\tvalid's rmse: 2341.95\n",
      "[61]\ttrain's rmse: 2281.16\tvalid's rmse: 2341.53\n",
      "[62]\ttrain's rmse: 2280.33\tvalid's rmse: 2340.74\n",
      "[63]\ttrain's rmse: 2279.69\tvalid's rmse: 2340.46\n",
      "[64]\ttrain's rmse: 2277.7\tvalid's rmse: 2338.17\n",
      "[65]\ttrain's rmse: 2275.52\tvalid's rmse: 2336.45\n",
      "[66]\ttrain's rmse: 2271.14\tvalid's rmse: 2332.08\n",
      "[67]\ttrain's rmse: 2269.75\tvalid's rmse: 2330.62\n",
      "[68]\ttrain's rmse: 2268.51\tvalid's rmse: 2329.89\n",
      "[69]\ttrain's rmse: 2268.06\tvalid's rmse: 2330.17\n",
      "[70]\ttrain's rmse: 2267.13\tvalid's rmse: 2329.15\n",
      "[71]\ttrain's rmse: 2266.47\tvalid's rmse: 2330.08\n",
      "[72]\ttrain's rmse: 2263.65\tvalid's rmse: 2327.89\n",
      "[73]\ttrain's rmse: 2259.94\tvalid's rmse: 2324.29\n",
      "[74]\ttrain's rmse: 2258.73\tvalid's rmse: 2323\n",
      "[75]\ttrain's rmse: 2257.75\tvalid's rmse: 2322.22\n",
      "[76]\ttrain's rmse: 2255.45\tvalid's rmse: 2320.42\n",
      "[77]\ttrain's rmse: 2254.9\tvalid's rmse: 2319.83\n",
      "[78]\ttrain's rmse: 2251.75\tvalid's rmse: 2316.84\n",
      "[79]\ttrain's rmse: 2251.2\tvalid's rmse: 2318.15\n",
      "[80]\ttrain's rmse: 2249.1\tvalid's rmse: 2316.47\n",
      "[81]\ttrain's rmse: 2248.65\tvalid's rmse: 2317.28\n",
      "[82]\ttrain's rmse: 2247.67\tvalid's rmse: 2316.3\n",
      "[83]\ttrain's rmse: 2247.3\tvalid's rmse: 2315.92\n",
      "[84]\ttrain's rmse: 2244.71\tvalid's rmse: 2313.19\n",
      "[85]\ttrain's rmse: 2243.91\tvalid's rmse: 2312.64\n",
      "[86]\ttrain's rmse: 2242.24\tvalid's rmse: 2311.06\n",
      "[87]\ttrain's rmse: 2240.51\tvalid's rmse: 2309.37\n",
      "[88]\ttrain's rmse: 2240.01\tvalid's rmse: 2309.49\n",
      "[89]\ttrain's rmse: 2239.56\tvalid's rmse: 2309.55\n",
      "[90]\ttrain's rmse: 2237.25\tvalid's rmse: 2307.16\n",
      "[91]\ttrain's rmse: 2236.83\tvalid's rmse: 2306.9\n",
      "[92]\ttrain's rmse: 2235.44\tvalid's rmse: 2305.53\n",
      "[93]\ttrain's rmse: 2235.01\tvalid's rmse: 2305.7\n",
      "[94]\ttrain's rmse: 2233.95\tvalid's rmse: 2304.87\n",
      "[95]\ttrain's rmse: 2232.14\tvalid's rmse: 2303.05\n",
      "[96]\ttrain's rmse: 2231.5\tvalid's rmse: 2302.62\n",
      "[97]\ttrain's rmse: 2230.75\tvalid's rmse: 2301.77\n",
      "[98]\ttrain's rmse: 2230.36\tvalid's rmse: 2301.88\n",
      "[99]\ttrain's rmse: 2229.9\tvalid's rmse: 2301.4\n",
      "[100]\ttrain's rmse: 2229.57\tvalid's rmse: 2302.44\n",
      "RMSPE RMSPE RMSPE RMSPE RMSPE RMSPE: 0.4585\n",
      "i ==================================================================  3\n",
      "[LightGBM] [Info] Total Bins 325\n",
      "[LightGBM] [Info] Number of data points in the train set: 762906, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 5720.633372\n",
      "[1]\ttrain's rmse: 3590.11\tvalid's rmse: 3752.45\n",
      "[2]\ttrain's rmse: 3405.2\tvalid's rmse: 3559.09\n",
      "[3]\ttrain's rmse: 3247.06\tvalid's rmse: 3387.59\n",
      "[4]\ttrain's rmse: 3113.41\tvalid's rmse: 3249.01\n",
      "[5]\ttrain's rmse: 2998.84\tvalid's rmse: 3127.14\n",
      "[6]\ttrain's rmse: 2903.44\tvalid's rmse: 3026.1\n",
      "[7]\ttrain's rmse: 2822.51\tvalid's rmse: 2941.3\n",
      "[8]\ttrain's rmse: 2752.71\tvalid's rmse: 2868.94\n",
      "[9]\ttrain's rmse: 2696.93\tvalid's rmse: 2812.54\n",
      "[10]\ttrain's rmse: 2650.56\tvalid's rmse: 2764.93\n",
      "[11]\ttrain's rmse: 2611.88\tvalid's rmse: 2726.3\n",
      "[12]\ttrain's rmse: 2575.16\tvalid's rmse: 2688.95\n",
      "[13]\ttrain's rmse: 2548.44\tvalid's rmse: 2663.33\n",
      "[14]\ttrain's rmse: 2522.57\tvalid's rmse: 2636.83\n",
      "[15]\ttrain's rmse: 2503.96\tvalid's rmse: 2617.77\n",
      "[16]\ttrain's rmse: 2484.26\tvalid's rmse: 2598.36\n",
      "[17]\ttrain's rmse: 2467.53\tvalid's rmse: 2581.3\n",
      "[18]\ttrain's rmse: 2454.11\tvalid's rmse: 2567.59\n",
      "[19]\ttrain's rmse: 2442.07\tvalid's rmse: 2555.39\n",
      "[20]\ttrain's rmse: 2431.27\tvalid's rmse: 2544.72\n",
      "[21]\ttrain's rmse: 2422.44\tvalid's rmse: 2536.16\n",
      "[22]\ttrain's rmse: 2414.06\tvalid's rmse: 2527.69\n",
      "[23]\ttrain's rmse: 2408.51\tvalid's rmse: 2521.85\n",
      "[24]\ttrain's rmse: 2399.11\tvalid's rmse: 2512.86\n",
      "[25]\ttrain's rmse: 2394.89\tvalid's rmse: 2509.42\n",
      "[26]\ttrain's rmse: 2388.55\tvalid's rmse: 2503.44\n",
      "[27]\ttrain's rmse: 2381.03\tvalid's rmse: 2496.44\n",
      "[28]\ttrain's rmse: 2372.63\tvalid's rmse: 2488.06\n",
      "[29]\ttrain's rmse: 2369.39\tvalid's rmse: 2486.79\n",
      "[30]\ttrain's rmse: 2366.32\tvalid's rmse: 2484.71\n",
      "[31]\ttrain's rmse: 2359.21\tvalid's rmse: 2477.77\n",
      "[32]\ttrain's rmse: 2351.18\tvalid's rmse: 2470.42\n",
      "[33]\ttrain's rmse: 2348.58\tvalid's rmse: 2467.27\n",
      "[34]\ttrain's rmse: 2346.76\tvalid's rmse: 2465.24\n",
      "[35]\ttrain's rmse: 2339.01\tvalid's rmse: 2457.55\n",
      "[36]\ttrain's rmse: 2337.01\tvalid's rmse: 2457.88\n",
      "[37]\ttrain's rmse: 2329.89\tvalid's rmse: 2451.52\n",
      "[38]\ttrain's rmse: 2327.97\tvalid's rmse: 2450.2\n",
      "[39]\ttrain's rmse: 2326.62\tvalid's rmse: 2450.13\n",
      "[40]\ttrain's rmse: 2321.04\tvalid's rmse: 2444.97\n",
      "[41]\ttrain's rmse: 2319.91\tvalid's rmse: 2445.76\n",
      "[42]\ttrain's rmse: 2315.52\tvalid's rmse: 2441.65\n",
      "[43]\ttrain's rmse: 2311.84\tvalid's rmse: 2438.46\n",
      "[44]\ttrain's rmse: 2310.08\tvalid's rmse: 2438.63\n",
      "[45]\ttrain's rmse: 2308.99\tvalid's rmse: 2436.96\n",
      "[46]\ttrain's rmse: 2304.74\tvalid's rmse: 2432.99\n",
      "[47]\ttrain's rmse: 2301.12\tvalid's rmse: 2429.58\n",
      "[48]\ttrain's rmse: 2300.14\tvalid's rmse: 2428.13\n",
      "[49]\ttrain's rmse: 2295.65\tvalid's rmse: 2423.6\n",
      "[50]\ttrain's rmse: 2293.29\tvalid's rmse: 2421.65\n",
      "[51]\ttrain's rmse: 2288.64\tvalid's rmse: 2417.6\n",
      "[52]\ttrain's rmse: 2287.74\tvalid's rmse: 2417.25\n",
      "[53]\ttrain's rmse: 2284.49\tvalid's rmse: 2414.37\n",
      "[54]\ttrain's rmse: 2281.97\tvalid's rmse: 2412.02\n",
      "[55]\ttrain's rmse: 2281.1\tvalid's rmse: 2414.98\n",
      "[56]\ttrain's rmse: 2276.92\tvalid's rmse: 2411.38\n",
      "[57]\ttrain's rmse: 2276.04\tvalid's rmse: 2414.22\n",
      "[58]\ttrain's rmse: 2273.87\tvalid's rmse: 2412.56\n",
      "[59]\ttrain's rmse: 2273.03\tvalid's rmse: 2412.38\n",
      "[60]\ttrain's rmse: 2270.89\tvalid's rmse: 2410.59\n",
      "[61]\ttrain's rmse: 2268.47\tvalid's rmse: 2408.45\n",
      "[62]\ttrain's rmse: 2267.39\tvalid's rmse: 2408.36\n",
      "[63]\ttrain's rmse: 2266.72\tvalid's rmse: 2407.62\n",
      "[64]\ttrain's rmse: 2264.78\tvalid's rmse: 2405.64\n",
      "[65]\ttrain's rmse: 2261.75\tvalid's rmse: 2402.73\n",
      "[66]\ttrain's rmse: 2260.21\tvalid's rmse: 2401.46\n",
      "[67]\ttrain's rmse: 2258.69\tvalid's rmse: 2400.14\n",
      "[68]\ttrain's rmse: 2257.34\tvalid's rmse: 2399.15\n",
      "[69]\ttrain's rmse: 2256.57\tvalid's rmse: 2398.78\n",
      "[70]\ttrain's rmse: 2253.87\tvalid's rmse: 2396.59\n",
      "[71]\ttrain's rmse: 2253.19\tvalid's rmse: 2396.29\n",
      "[72]\ttrain's rmse: 2252.05\tvalid's rmse: 2395.37\n",
      "[73]\ttrain's rmse: 2250.79\tvalid's rmse: 2394.08\n",
      "[74]\ttrain's rmse: 2250.18\tvalid's rmse: 2394.07\n",
      "[75]\ttrain's rmse: 2248.87\tvalid's rmse: 2392.78\n",
      "[76]\ttrain's rmse: 2248.09\tvalid's rmse: 2392\n",
      "[77]\ttrain's rmse: 2245.23\tvalid's rmse: 2389.45\n",
      "[78]\ttrain's rmse: 2244.45\tvalid's rmse: 2388.79\n",
      "[79]\ttrain's rmse: 2242\tvalid's rmse: 2386.33\n",
      "[80]\ttrain's rmse: 2241.51\tvalid's rmse: 2387.35\n",
      "[81]\ttrain's rmse: 2240.77\tvalid's rmse: 2387.01\n",
      "[82]\ttrain's rmse: 2240.29\tvalid's rmse: 2387.84\n",
      "[83]\ttrain's rmse: 2237.84\tvalid's rmse: 2385.7\n",
      "[84]\ttrain's rmse: 2237.24\tvalid's rmse: 2385.2\n",
      "[85]\ttrain's rmse: 2236.8\tvalid's rmse: 2385.03\n",
      "[86]\ttrain's rmse: 2236.18\tvalid's rmse: 2384.43\n",
      "[87]\ttrain's rmse: 2234.12\tvalid's rmse: 2382.57\n",
      "[88]\ttrain's rmse: 2233.62\tvalid's rmse: 2382.53\n",
      "[89]\ttrain's rmse: 2231.64\tvalid's rmse: 2380.82\n",
      "[90]\ttrain's rmse: 2230.58\tvalid's rmse: 2380.04\n",
      "[91]\ttrain's rmse: 2228.93\tvalid's rmse: 2378.71\n",
      "[92]\ttrain's rmse: 2228.4\tvalid's rmse: 2378.26\n",
      "[93]\ttrain's rmse: 2227.3\tvalid's rmse: 2377.33\n",
      "[94]\ttrain's rmse: 2227.07\tvalid's rmse: 2377.07\n",
      "[95]\ttrain's rmse: 2226.55\tvalid's rmse: 2377.08\n",
      "[96]\ttrain's rmse: 2224.37\tvalid's rmse: 2375.12\n",
      "[97]\ttrain's rmse: 2223.59\tvalid's rmse: 2374.45\n",
      "[98]\ttrain's rmse: 2223.11\tvalid's rmse: 2374.76\n",
      "[99]\ttrain's rmse: 2222.7\tvalid's rmse: 2374.34\n",
      "[100]\ttrain's rmse: 2221.3\tvalid's rmse: 2373.31\n",
      "RMSPE RMSPE RMSPE RMSPE RMSPE RMSPE: 0.4347\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "modeldict = mpre2.load_models(TMP_DIR)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "load開始\n",
      "load終わりました\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "pred_dict = mpre2.mk_pred_dict(modeldict,test_x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "予測リストが入った辞書作成開始\n",
      "予測リストが入った辞書作成終了\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "pred_wei_average = mpre2.wei_average(pred_dict,len(test_x))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "複数モデルを使用した重み付き平均予測を開始します\n",
      "重み付き平均pred_wei_averageがreturnされます\n",
      "重み付き平均pred_wei_averageがreturnされました\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "subpred = pd.DataFrame(pred_wei_average)\r\n",
    "# subpred.sort_values('Sales')\r\n",
    "\r\n",
    "sub = pd.concat([test['Id'],subpred],axis=1)\r\n",
    "sub.columns = ['Id','Sales']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "mpre2.mk_output(df=sub,NOW=NOW,PRACTICE=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('rake4': conda)"
  },
  "interpreter": {
   "hash": "d9f87b01c5f363e537c38b2d60098718b3d41838537a2c7a8e52ee73e3d0a1c0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}