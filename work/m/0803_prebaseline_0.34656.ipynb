{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "'''\r\n",
    "差分内容\r\n",
    "- week dayofyer\r\n",
    "0.36472\r\n",
    "- storeテーブルのPromo2SinceWeek\tPromo2SinceYear\tPromoIntervalの情報以外を使用してtrainにMERGE\r\n",
    "\r\n",
    "'''"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n差分内容\\n- week dayofyer\\n0.36472\\n- storeテーブルのPromo2SinceWeek\\tPromo2SinceYear\\tPromoIntervalの情報以外を使用してtrainにMERGE\\n\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# main module\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import pandas_profiling as pdp\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "import lightgbm as lgb\r\n",
    "\r\n",
    "from sklearn.metrics import log_loss\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "\r\n",
    "import datetime\r\n",
    "import gc\r\n",
    "import logging\r\n",
    "import pickle\r\n",
    "from pickle import load\r\n",
    "import sys, os\r\n",
    "\r\n",
    "# -------------------------------------独自モジュール-------------------------------------\r\n",
    "sys.path.append('../src/') #モジュールが入っているディレクトリのパスを指定\r\n",
    "import eda\r\n",
    "import maprepro as mpre\r\n",
    "import maprepro2 as mpre2\r\n",
    "# import config\r\n",
    "# from utils import setup_logger, ModelFactory\r\n",
    "# -------------------------------------独自モジュール-------------------------------------"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "path = '../../input'\r\n",
    "sample = pd.read_csv(f'{path}/sample_submission.csv')\r\n",
    "store = pd.read_csv(f'{path}/store.csv')\r\n",
    "\r\n",
    "test = pd.read_csv(f'{path}/test.csv',\r\n",
    "                       parse_dates=['Date'],\r\n",
    "                       date_parser=(lambda dt: pd.to_datetime(dt, format='%Y-%m-%d')))\r\n",
    "\r\n",
    "train = pd.read_csv(f'{path}/train.csv',\r\n",
    "                       parse_dates=['Date'],\r\n",
    "                       date_parser=(lambda dt: pd.to_datetime(dt, format='%Y-%m-%d')))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\thyt\\anaconda3\\envs\\rake4\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# np.log1p(train.Sales).plot.hist(bins=100)\r\n",
    "train.query(\"Open == 0\").Sales.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    172817\n",
       "Name: Sales, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "train = train.sort_values('Date')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "def mk_YMD_DOY(df):\r\n",
    "    var_name = 'Date'\r\n",
    "    df[var_name + 'Year'] = pd.Index(df[var_name]).year\r\n",
    "    df[var_name + 'Month'] = pd.Index(df[var_name]).month\r\n",
    "    df[var_name + 'Week'] = pd.Index(df[var_name]).week\r\n",
    "    df[var_name + 'Day'] = pd.Index(df[var_name]).day\r\n",
    "    df[var_name + 'DayOfYear'] = pd.Index(df[var_name]).dayofyear\r\n",
    "    return df\r\n",
    "train = mk_YMD_DOY(train)\r\n",
    "test = mk_YMD_DOY(test)\r\n",
    "\r\n",
    "# 時系列データであり、時間に沿って変数periodを設定したとする\r\n",
    "def mk_period(df,testdata=False):\r\n",
    "    if testdata == False:\r\n",
    "        df['period'] = np.arange(0, len(df)) // (len(df) // 4)\r\n",
    "        df['period'] = np.clip(df['period'], 0, 3)\r\n",
    "        return df\r\n",
    "    else:\r\n",
    "        df['period'] = 4\r\n",
    "        return df\r\n",
    "\r\n",
    "train = mk_period(train)\r\n",
    "test = mk_period(test,testdata=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\thyt\\AppData\\Local\\Temp/ipykernel_14240/3274496651.py:5: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
      "  df[var_name + 'Week'] = pd.Index(df[var_name]).week\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "store"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Store StoreType Assortment  CompetitionDistance  \\\n",
       "0         1         c          a               1270.0   \n",
       "1         2         a          a                570.0   \n",
       "2         3         a          a              14130.0   \n",
       "3         4         c          c                620.0   \n",
       "4         5         a          a              29910.0   \n",
       "...     ...       ...        ...                  ...   \n",
       "1110   1111         a          a               1900.0   \n",
       "1111   1112         c          c               1880.0   \n",
       "1112   1113         a          c               9260.0   \n",
       "1113   1114         a          c                870.0   \n",
       "1114   1115         d          c               5350.0   \n",
       "\n",
       "      CompetitionOpenSinceMonth  CompetitionOpenSinceYear  Promo2  \\\n",
       "0                           9.0                    2008.0       0   \n",
       "1                          11.0                    2007.0       1   \n",
       "2                          12.0                    2006.0       1   \n",
       "3                           9.0                    2009.0       0   \n",
       "4                           4.0                    2015.0       0   \n",
       "...                         ...                       ...     ...   \n",
       "1110                        6.0                    2014.0       1   \n",
       "1111                        4.0                    2006.0       0   \n",
       "1112                        NaN                       NaN       0   \n",
       "1113                        NaN                       NaN       0   \n",
       "1114                        NaN                       NaN       1   \n",
       "\n",
       "      Promo2SinceWeek  Promo2SinceYear     PromoInterval  \n",
       "0                 NaN              NaN               NaN  \n",
       "1                13.0           2010.0   Jan,Apr,Jul,Oct  \n",
       "2                14.0           2011.0   Jan,Apr,Jul,Oct  \n",
       "3                 NaN              NaN               NaN  \n",
       "4                 NaN              NaN               NaN  \n",
       "...               ...              ...               ...  \n",
       "1110             31.0           2013.0   Jan,Apr,Jul,Oct  \n",
       "1111              NaN              NaN               NaN  \n",
       "1112              NaN              NaN               NaN  \n",
       "1113              NaN              NaN               NaN  \n",
       "1114             22.0           2012.0  Mar,Jun,Sept,Dec  \n",
       "\n",
       "[1115 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>620.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>29910.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1111</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>1112</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>1113</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>9260.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>1114</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>870.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>1115</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>5350.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Mar,Jun,Sept,Dec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "def mk_cat(df):\r\n",
    "    # intなので決定木系でないと使えない処理\r\n",
    "    store['StoreType'] = store['StoreType'].astype('category').cat.codes\r\n",
    "    store['Assortment'] = store['Assortment'].astype('category').cat.codes\r\n",
    "    return store\r\n",
    "store = mk_cat(store)\r\n",
    "use = ['Store','StoreType','Assortment','CompetitionDistance','CompetitionOpenSinceMonth','CompetitionOpenSinceYear','Promo2']\r\n",
    "train = pd.merge(train, store[use], how='left', on=['Store'])\r\n",
    "test = pd.merge(test, store[use], how='left', on=['Store'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "train['StateHoliday'] = train.StateHoliday.astype('category')\r\n",
    "test['StateHoliday'] = test.StateHoliday.astype('category')\r\n",
    "\r\n",
    "alltmp = sorted(train.columns)\r\n",
    "target = ['Sales']\r\n",
    "notuse = ['Id','Date']\r\n",
    "use = ['Store','DayOfWeek','Open','Promo','StateHoliday','SchoolHoliday','period',\r\n",
    "        'DateYear','DateMonth','DateWeek','DateDay']\r\n",
    "\r\n",
    "# unknown--'Customers'column\r\n",
    "use2 = ['Store','DayOfWeek','Open','Promo','StateHoliday','SchoolHoliday','StoreType','Assortment','CompetitionDistance',\r\n",
    "        'CompetitionOpenSinceMonth','CompetitionOpenSinceYear','Promo2','DateYear','DateMonth','DateWeek','DateDay','DateDayOfYear','period']\r\n",
    "        \r\n",
    "categorical_features = ['StateHoliday']\r\n",
    "\r\n",
    "train_y = train[target]\r\n",
    "train_x = train[use2]\r\n",
    "test_x = test[use2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "import warnings\r\n",
    "warnings.simplefilter('ignore')\r\n",
    "train_x = eda.reduce_mem_usage(train_x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "start size(BEFORE): 123.20 Mb\n",
      "Mem. usage decreased to 32.98 Mb (AFTER:73.2% reduction)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "# --------------------------------------------------\r\n",
    "import maprepro2 as mpre2\r\n",
    "NOW,TMP_DIR = mpre2.mk_dir()\r\n",
    "gc.collect()\r\n",
    "# --------------------------------------------------\r\n",
    "\r\n",
    "va_period_list = [1, 2, 3]\r\n",
    "for va_period in va_period_list:\r\n",
    "    print('i ================================================================== ',va_period)\r\n",
    "    is_tr = train_x['period'] < va_period\r\n",
    "    is_va = train_x['period'] == va_period\r\n",
    "    tr_x, va_x = train_x[is_tr], train_x[is_va]\r\n",
    "    tr_y, va_y = train_y[is_tr], train_y[is_va]\r\n",
    "    \r\n",
    "    lgb_train = lgb.Dataset(tr_x, tr_y)\r\n",
    "    lgb_eval = lgb.Dataset(va_x, va_y)\r\n",
    "\r\n",
    "    # ハイパーパラメータの設定\r\n",
    "    params = {'objective': 'regression',\r\n",
    "                'seed': 71,\r\n",
    "                'verbose': 1,\r\n",
    "                'metrics': 'rmse',\r\n",
    "                'force_col_wise':'true' # メモリが足りないから\r\n",
    "                }\r\n",
    "    num_round = 100\r\n",
    "\r\n",
    "    # 学習の実行\r\n",
    "    categorical_features = categorical_features\r\n",
    "    model = lgb.train(params, lgb_train, num_boost_round=num_round,\r\n",
    "                    categorical_feature=categorical_features,\r\n",
    "                    valid_names=['train', 'valid'], valid_sets=[lgb_train, lgb_eval],\r\n",
    "                    )\r\n",
    "\r\n",
    "\r\n",
    "    tmpfile = f'{TMP_DIR}/trained_model{va_period}.pkl'\r\n",
    "    pickle.dump(model, open(tmpfile, 'wb'))\r\n",
    "\r\n",
    "    # バリデーションデータでのスコアの確認\r\n",
    "    va_pred = model.predict(va_x); va_pred = va_pred.reshape(-1, 1)\r\n",
    "\r\n",
    "    # Open=0の日はすべてSalesが0で、0以外を予測することはありえないので0で更新(モデルは自然数を予測しているみたいだが、\r\n",
    "    # Open=0ならSales=0をモデルに教えられていないということ)\r\n",
    "    tmp =va_y['Sales']==0\r\n",
    "    va_pred[tmp]=0\r\n",
    "    va_pred=va_pred+1; va_y=va_y+1\r\n",
    "\r\n",
    "    # --------------------------------------------------\r\n",
    "    # score = mean_squared_error(va_y, va_pred)\r\n",
    "    RMSPE = np.sqrt(np.mean(((  (va_y-va_pred)/va_y)**2) )).values\r\n",
    "    RMSPE = RMSPE.astype(float)[0] # printのために単一の数値にしたかった\r\n",
    "    # score = log_loss(va_y, va_pred)\r\n",
    "    print('RMSPE RMSPE RMSPE RMSPE RMSPE RMSPE: {:.4f}'.format(RMSPE))\r\n",
    "    # --------------------------------------------------\r\n",
    "\r\n",
    "    del model # 学習済みモデルを削除\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "i ==================================================================  1\n",
      "[LightGBM] [Info] Total Bins 880\n",
      "[LightGBM] [Info] Number of data points in the train set: 254302, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 5576.839962\n",
      "[1]\ttrain's rmse: 3492.89\tvalid's rmse: 3626.56\n",
      "[2]\ttrain's rmse: 3298.58\tvalid's rmse: 3444.32\n",
      "[3]\ttrain's rmse: 3129.87\tvalid's rmse: 3285.79\n",
      "[4]\ttrain's rmse: 2984.19\tvalid's rmse: 3149.43\n",
      "[5]\ttrain's rmse: 2861.77\tvalid's rmse: 3035.07\n",
      "[6]\ttrain's rmse: 2755.81\tvalid's rmse: 2935.07\n",
      "[7]\ttrain's rmse: 2666.75\tvalid's rmse: 2852.04\n",
      "[8]\ttrain's rmse: 2589.89\tvalid's rmse: 2781.03\n",
      "[9]\ttrain's rmse: 2522.46\tvalid's rmse: 2719.04\n",
      "[10]\ttrain's rmse: 2466.54\tvalid's rmse: 2663.68\n",
      "[11]\ttrain's rmse: 2418.06\tvalid's rmse: 2620.77\n",
      "[12]\ttrain's rmse: 2372.58\tvalid's rmse: 2578.24\n",
      "[13]\ttrain's rmse: 2335.03\tvalid's rmse: 2542.37\n",
      "[14]\ttrain's rmse: 2305.2\tvalid's rmse: 2513.32\n",
      "[15]\ttrain's rmse: 2268.6\tvalid's rmse: 2482.1\n",
      "[16]\ttrain's rmse: 2244.14\tvalid's rmse: 2459.33\n",
      "[17]\ttrain's rmse: 2215.03\tvalid's rmse: 2433.94\n",
      "[18]\ttrain's rmse: 2195.29\tvalid's rmse: 2415.41\n",
      "[19]\ttrain's rmse: 2177.24\tvalid's rmse: 2399.59\n",
      "[20]\ttrain's rmse: 2153.27\tvalid's rmse: 2379.15\n",
      "[21]\ttrain's rmse: 2125.91\tvalid's rmse: 2355.75\n",
      "[22]\ttrain's rmse: 2110.85\tvalid's rmse: 2340.59\n",
      "[23]\ttrain's rmse: 2083.92\tvalid's rmse: 2316.63\n",
      "[24]\ttrain's rmse: 2073.56\tvalid's rmse: 2309.03\n",
      "[25]\ttrain's rmse: 2051.4\tvalid's rmse: 2289.15\n",
      "[26]\ttrain's rmse: 2025.51\tvalid's rmse: 2265.86\n",
      "[27]\ttrain's rmse: 2017.35\tvalid's rmse: 2258.58\n",
      "[28]\ttrain's rmse: 1996.74\tvalid's rmse: 2240.77\n",
      "[29]\ttrain's rmse: 1989.65\tvalid's rmse: 2235.84\n",
      "[30]\ttrain's rmse: 1971.9\tvalid's rmse: 2220.28\n",
      "[31]\ttrain's rmse: 1964.15\tvalid's rmse: 2213.8\n",
      "[32]\ttrain's rmse: 1954.22\tvalid's rmse: 2204.06\n",
      "[33]\ttrain's rmse: 1934.27\tvalid's rmse: 2186.43\n",
      "[34]\ttrain's rmse: 1928.3\tvalid's rmse: 2181.39\n",
      "[35]\ttrain's rmse: 1921.71\tvalid's rmse: 2175.23\n",
      "[36]\ttrain's rmse: 1901.82\tvalid's rmse: 2158.2\n",
      "[37]\ttrain's rmse: 1888.71\tvalid's rmse: 2146.75\n",
      "[38]\ttrain's rmse: 1883.43\tvalid's rmse: 2143.65\n",
      "[39]\ttrain's rmse: 1872.07\tvalid's rmse: 2133.83\n",
      "[40]\ttrain's rmse: 1859.99\tvalid's rmse: 2124.13\n",
      "[41]\ttrain's rmse: 1855.65\tvalid's rmse: 2121.95\n",
      "[42]\ttrain's rmse: 1849.16\tvalid's rmse: 2115.92\n",
      "[43]\ttrain's rmse: 1839.2\tvalid's rmse: 2107.27\n",
      "[44]\ttrain's rmse: 1830.11\tvalid's rmse: 2099.21\n",
      "[45]\ttrain's rmse: 1815.61\tvalid's rmse: 2086.93\n",
      "[46]\ttrain's rmse: 1810.35\tvalid's rmse: 2082.65\n",
      "[47]\ttrain's rmse: 1800.21\tvalid's rmse: 2074.38\n",
      "[48]\ttrain's rmse: 1789.44\tvalid's rmse: 2065.34\n",
      "[49]\ttrain's rmse: 1780.85\tvalid's rmse: 2058.93\n",
      "[50]\ttrain's rmse: 1776.53\tvalid's rmse: 2056.54\n",
      "[51]\ttrain's rmse: 1769.59\tvalid's rmse: 2050.79\n",
      "[52]\ttrain's rmse: 1761.88\tvalid's rmse: 2045.42\n",
      "[53]\ttrain's rmse: 1758.93\tvalid's rmse: 2043.97\n",
      "[54]\ttrain's rmse: 1753.34\tvalid's rmse: 2038.41\n",
      "[55]\ttrain's rmse: 1743.3\tvalid's rmse: 2030.01\n",
      "[56]\ttrain's rmse: 1737.07\tvalid's rmse: 2025.67\n",
      "[57]\ttrain's rmse: 1728.48\tvalid's rmse: 2018.12\n",
      "[58]\ttrain's rmse: 1719.88\tvalid's rmse: 2011.82\n",
      "[59]\ttrain's rmse: 1715.03\tvalid's rmse: 2006.98\n",
      "[60]\ttrain's rmse: 1711.48\tvalid's rmse: 2005.24\n",
      "[61]\ttrain's rmse: 1706.24\tvalid's rmse: 2001.17\n",
      "[62]\ttrain's rmse: 1697.34\tvalid's rmse: 1994.33\n",
      "[63]\ttrain's rmse: 1687.27\tvalid's rmse: 1985.75\n",
      "[64]\ttrain's rmse: 1680.16\tvalid's rmse: 1979.84\n",
      "[65]\ttrain's rmse: 1676.99\tvalid's rmse: 1978.24\n",
      "[66]\ttrain's rmse: 1671.05\tvalid's rmse: 1973.26\n",
      "[67]\ttrain's rmse: 1661.09\tvalid's rmse: 1964.75\n",
      "[68]\ttrain's rmse: 1656.14\tvalid's rmse: 1961.24\n",
      "[69]\ttrain's rmse: 1650.7\tvalid's rmse: 1957.22\n",
      "[70]\ttrain's rmse: 1642.19\tvalid's rmse: 1950.06\n",
      "[71]\ttrain's rmse: 1634.03\tvalid's rmse: 1942.99\n",
      "[72]\ttrain's rmse: 1632.03\tvalid's rmse: 1943.35\n",
      "[73]\ttrain's rmse: 1627.66\tvalid's rmse: 1940.21\n",
      "[74]\ttrain's rmse: 1622.54\tvalid's rmse: 1936.02\n",
      "[75]\ttrain's rmse: 1618.07\tvalid's rmse: 1932.67\n",
      "[76]\ttrain's rmse: 1613.44\tvalid's rmse: 1929.08\n",
      "[77]\ttrain's rmse: 1605.15\tvalid's rmse: 1922.16\n",
      "[78]\ttrain's rmse: 1598.62\tvalid's rmse: 1916.85\n",
      "[79]\ttrain's rmse: 1595.2\tvalid's rmse: 1914.24\n",
      "[80]\ttrain's rmse: 1592.54\tvalid's rmse: 1912.57\n",
      "[81]\ttrain's rmse: 1587.89\tvalid's rmse: 1908.13\n",
      "[82]\ttrain's rmse: 1582.19\tvalid's rmse: 1904.53\n",
      "[83]\ttrain's rmse: 1579.6\tvalid's rmse: 1903.13\n",
      "[84]\ttrain's rmse: 1575.75\tvalid's rmse: 1900.02\n",
      "[85]\ttrain's rmse: 1568.06\tvalid's rmse: 1893.7\n",
      "[86]\ttrain's rmse: 1563.75\tvalid's rmse: 1890.71\n",
      "[87]\ttrain's rmse: 1560.62\tvalid's rmse: 1888.34\n",
      "[88]\ttrain's rmse: 1557.59\tvalid's rmse: 1886.12\n",
      "[89]\ttrain's rmse: 1555.06\tvalid's rmse: 1885.4\n",
      "[90]\ttrain's rmse: 1550.06\tvalid's rmse: 1881.08\n",
      "[91]\ttrain's rmse: 1547.31\tvalid's rmse: 1879.41\n",
      "[92]\ttrain's rmse: 1545.82\tvalid's rmse: 1879.36\n",
      "[93]\ttrain's rmse: 1541.99\tvalid's rmse: 1876.87\n",
      "[94]\ttrain's rmse: 1537.54\tvalid's rmse: 1873.52\n",
      "[95]\ttrain's rmse: 1534.7\tvalid's rmse: 1871.26\n",
      "[96]\ttrain's rmse: 1531.88\tvalid's rmse: 1869.08\n",
      "[97]\ttrain's rmse: 1527.22\tvalid's rmse: 1865.42\n",
      "[98]\ttrain's rmse: 1525.15\tvalid's rmse: 1864.02\n",
      "[99]\ttrain's rmse: 1521.4\tvalid's rmse: 1860.97\n",
      "[100]\ttrain's rmse: 1515.16\tvalid's rmse: 1856.2\n",
      "RMSPE RMSPE RMSPE RMSPE RMSPE RMSPE: 0.3122\n",
      "i ==================================================================  2\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 508604, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5648.631594\n",
      "[1]\ttrain's rmse: 3553.83\tvalid's rmse: 3632.09\n",
      "[2]\ttrain's rmse: 3357.76\tvalid's rmse: 3433.86\n",
      "[3]\ttrain's rmse: 3188.51\tvalid's rmse: 3264.69\n",
      "[4]\ttrain's rmse: 3044.88\tvalid's rmse: 3117.58\n",
      "[5]\ttrain's rmse: 2919.88\tvalid's rmse: 2989.05\n",
      "[6]\ttrain's rmse: 2812.29\tvalid's rmse: 2878\n",
      "[7]\ttrain's rmse: 2722.99\tvalid's rmse: 2787.34\n",
      "[8]\ttrain's rmse: 2645.2\tvalid's rmse: 2705.47\n",
      "[9]\ttrain's rmse: 2577.61\tvalid's rmse: 2634.24\n",
      "[10]\ttrain's rmse: 2519.61\tvalid's rmse: 2573.99\n",
      "[11]\ttrain's rmse: 2471.2\tvalid's rmse: 2525\n",
      "[12]\ttrain's rmse: 2427.64\tvalid's rmse: 2479.25\n",
      "[13]\ttrain's rmse: 2392.36\tvalid's rmse: 2442.1\n",
      "[14]\ttrain's rmse: 2358.45\tvalid's rmse: 2405.35\n",
      "[15]\ttrain's rmse: 2330.55\tvalid's rmse: 2376.13\n",
      "[16]\ttrain's rmse: 2306.88\tvalid's rmse: 2351.92\n",
      "[17]\ttrain's rmse: 2277.71\tvalid's rmse: 2318.62\n",
      "[18]\ttrain's rmse: 2258.39\tvalid's rmse: 2298.19\n",
      "[19]\ttrain's rmse: 2232.52\tvalid's rmse: 2268.89\n",
      "[20]\ttrain's rmse: 2211.06\tvalid's rmse: 2248.56\n",
      "[21]\ttrain's rmse: 2197.49\tvalid's rmse: 2235.27\n",
      "[22]\ttrain's rmse: 2169.04\tvalid's rmse: 2206.06\n",
      "[23]\ttrain's rmse: 2143.84\tvalid's rmse: 2180.71\n",
      "[24]\ttrain's rmse: 2134.65\tvalid's rmse: 2173.46\n",
      "[25]\ttrain's rmse: 2109.5\tvalid's rmse: 2149.64\n",
      "[26]\ttrain's rmse: 2090.84\tvalid's rmse: 2132.29\n",
      "[27]\ttrain's rmse: 2082.73\tvalid's rmse: 2124.59\n",
      "[28]\ttrain's rmse: 2066.09\tvalid's rmse: 2107.51\n",
      "[29]\ttrain's rmse: 2059.03\tvalid's rmse: 2101.38\n",
      "[30]\ttrain's rmse: 2037.37\tvalid's rmse: 2079.41\n",
      "[31]\ttrain's rmse: 2027.61\tvalid's rmse: 2069.86\n",
      "[32]\ttrain's rmse: 2019.9\tvalid's rmse: 2062.95\n",
      "[33]\ttrain's rmse: 2011.95\tvalid's rmse: 2055.93\n",
      "[34]\ttrain's rmse: 1998.72\tvalid's rmse: 2042.98\n",
      "[35]\ttrain's rmse: 1985.57\tvalid's rmse: 2028.07\n",
      "[36]\ttrain's rmse: 1974.55\tvalid's rmse: 2017.52\n",
      "[37]\ttrain's rmse: 1964.3\tvalid's rmse: 2007.78\n",
      "[38]\ttrain's rmse: 1955.3\tvalid's rmse: 1998.26\n",
      "[39]\ttrain's rmse: 1944.99\tvalid's rmse: 1988.81\n",
      "[40]\ttrain's rmse: 1939.19\tvalid's rmse: 1982.79\n",
      "[41]\ttrain's rmse: 1926.21\tvalid's rmse: 1969.37\n",
      "[42]\ttrain's rmse: 1921\tvalid's rmse: 1965.37\n",
      "[43]\ttrain's rmse: 1908.13\tvalid's rmse: 1952.82\n",
      "[44]\ttrain's rmse: 1894.58\tvalid's rmse: 1939.54\n",
      "[45]\ttrain's rmse: 1881.89\tvalid's rmse: 1927.6\n",
      "[46]\ttrain's rmse: 1878.25\tvalid's rmse: 1924.7\n",
      "[47]\ttrain's rmse: 1875.06\tvalid's rmse: 1923.05\n",
      "[48]\ttrain's rmse: 1865.46\tvalid's rmse: 1914.2\n",
      "[49]\ttrain's rmse: 1858.02\tvalid's rmse: 1906.39\n",
      "[50]\ttrain's rmse: 1849.16\tvalid's rmse: 1898.76\n",
      "[51]\ttrain's rmse: 1842.69\tvalid's rmse: 1892.73\n",
      "[52]\ttrain's rmse: 1839.67\tvalid's rmse: 1890.1\n",
      "[53]\ttrain's rmse: 1827.7\tvalid's rmse: 1877.99\n",
      "[54]\ttrain's rmse: 1818.79\tvalid's rmse: 1868.17\n",
      "[55]\ttrain's rmse: 1807.34\tvalid's rmse: 1857.66\n",
      "[56]\ttrain's rmse: 1803.7\tvalid's rmse: 1854.76\n",
      "[57]\ttrain's rmse: 1796.28\tvalid's rmse: 1848.15\n",
      "[58]\ttrain's rmse: 1789.78\tvalid's rmse: 1842.34\n",
      "[59]\ttrain's rmse: 1782.63\tvalid's rmse: 1835.76\n",
      "[60]\ttrain's rmse: 1775.2\tvalid's rmse: 1828.12\n",
      "[61]\ttrain's rmse: 1768.94\tvalid's rmse: 1822.42\n",
      "[62]\ttrain's rmse: 1766.59\tvalid's rmse: 1821.63\n",
      "[63]\ttrain's rmse: 1758.74\tvalid's rmse: 1813.91\n",
      "[64]\ttrain's rmse: 1751.74\tvalid's rmse: 1806.82\n",
      "[65]\ttrain's rmse: 1745.93\tvalid's rmse: 1800.52\n",
      "[66]\ttrain's rmse: 1738.88\tvalid's rmse: 1793.79\n",
      "[67]\ttrain's rmse: 1733.81\tvalid's rmse: 1788.63\n",
      "[68]\ttrain's rmse: 1728.13\tvalid's rmse: 1783.05\n",
      "[69]\ttrain's rmse: 1720.97\tvalid's rmse: 1776.89\n",
      "[70]\ttrain's rmse: 1717.64\tvalid's rmse: 1774.03\n",
      "[71]\ttrain's rmse: 1712.23\tvalid's rmse: 1769.29\n",
      "[72]\ttrain's rmse: 1707.5\tvalid's rmse: 1765.54\n",
      "[73]\ttrain's rmse: 1702.35\tvalid's rmse: 1760.85\n",
      "[74]\ttrain's rmse: 1697.28\tvalid's rmse: 1756.46\n",
      "[75]\ttrain's rmse: 1693.18\tvalid's rmse: 1752.32\n",
      "[76]\ttrain's rmse: 1691.15\tvalid's rmse: 1752.41\n",
      "[77]\ttrain's rmse: 1687.15\tvalid's rmse: 1748.12\n",
      "[78]\ttrain's rmse: 1681.71\tvalid's rmse: 1743.6\n",
      "[79]\ttrain's rmse: 1675.14\tvalid's rmse: 1737.79\n",
      "[80]\ttrain's rmse: 1670.57\tvalid's rmse: 1733.9\n",
      "[81]\ttrain's rmse: 1666.31\tvalid's rmse: 1729.18\n",
      "[82]\ttrain's rmse: 1659.83\tvalid's rmse: 1722.63\n",
      "[83]\ttrain's rmse: 1655.47\tvalid's rmse: 1718.33\n",
      "[84]\ttrain's rmse: 1649.68\tvalid's rmse: 1713.32\n",
      "[85]\ttrain's rmse: 1643.65\tvalid's rmse: 1707.58\n",
      "[86]\ttrain's rmse: 1640\tvalid's rmse: 1704.42\n",
      "[87]\ttrain's rmse: 1637.96\tvalid's rmse: 1702.91\n",
      "[88]\ttrain's rmse: 1632.69\tvalid's rmse: 1697.76\n",
      "[89]\ttrain's rmse: 1629.52\tvalid's rmse: 1695.26\n",
      "[90]\ttrain's rmse: 1620.64\tvalid's rmse: 1686.32\n",
      "[91]\ttrain's rmse: 1615.38\tvalid's rmse: 1681.38\n",
      "[92]\ttrain's rmse: 1608.26\tvalid's rmse: 1674.54\n",
      "[93]\ttrain's rmse: 1601.35\tvalid's rmse: 1667.81\n",
      "[94]\ttrain's rmse: 1595.16\tvalid's rmse: 1661.25\n",
      "[95]\ttrain's rmse: 1591.46\tvalid's rmse: 1657.74\n",
      "[96]\ttrain's rmse: 1588.82\tvalid's rmse: 1656.41\n",
      "[97]\ttrain's rmse: 1585.62\tvalid's rmse: 1653.11\n",
      "[98]\ttrain's rmse: 1579.36\tvalid's rmse: 1646.97\n",
      "[99]\ttrain's rmse: 1573.51\tvalid's rmse: 1641.98\n",
      "[100]\ttrain's rmse: 1570.19\tvalid's rmse: 1638.87\n",
      "RMSPE RMSPE RMSPE RMSPE RMSPE RMSPE: 0.3408\n",
      "i ==================================================================  3\n",
      "[LightGBM] [Info] Total Bins 935\n",
      "[LightGBM] [Info] Number of data points in the train set: 762906, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5720.633372\n",
      "[1]\ttrain's rmse: 3577.01\tvalid's rmse: 3746.28\n",
      "[2]\ttrain's rmse: 3377.63\tvalid's rmse: 3543.51\n",
      "[3]\ttrain's rmse: 3207.85\tvalid's rmse: 3368.42\n",
      "[4]\ttrain's rmse: 3059.32\tvalid's rmse: 3214.37\n",
      "[5]\ttrain's rmse: 2933.78\tvalid's rmse: 3081.55\n",
      "[6]\ttrain's rmse: 2827.58\tvalid's rmse: 2969.78\n",
      "[7]\ttrain's rmse: 2736.27\tvalid's rmse: 2869.58\n",
      "[8]\ttrain's rmse: 2657.53\tvalid's rmse: 2788.47\n",
      "[9]\ttrain's rmse: 2590.57\tvalid's rmse: 2716.07\n",
      "[10]\ttrain's rmse: 2532.57\tvalid's rmse: 2655.7\n",
      "[11]\ttrain's rmse: 2480.76\tvalid's rmse: 2601.88\n",
      "[12]\ttrain's rmse: 2439.24\tvalid's rmse: 2558.48\n",
      "[13]\ttrain's rmse: 2404.36\tvalid's rmse: 2520.07\n",
      "[14]\ttrain's rmse: 2372.53\tvalid's rmse: 2486.6\n",
      "[15]\ttrain's rmse: 2341.9\tvalid's rmse: 2454.67\n",
      "[16]\ttrain's rmse: 2317.16\tvalid's rmse: 2428.68\n",
      "[17]\ttrain's rmse: 2292.77\tvalid's rmse: 2401.69\n",
      "[18]\ttrain's rmse: 2270.87\tvalid's rmse: 2376.73\n",
      "[19]\ttrain's rmse: 2253.18\tvalid's rmse: 2359.18\n",
      "[20]\ttrain's rmse: 2229\tvalid's rmse: 2335.61\n",
      "[21]\ttrain's rmse: 2192.77\tvalid's rmse: 2299.58\n",
      "[22]\ttrain's rmse: 2180.64\tvalid's rmse: 2286.69\n",
      "[23]\ttrain's rmse: 2152\tvalid's rmse: 2258.38\n",
      "[24]\ttrain's rmse: 2135.01\tvalid's rmse: 2238.57\n",
      "[25]\ttrain's rmse: 2111.49\tvalid's rmse: 2214.87\n",
      "[26]\ttrain's rmse: 2102.86\tvalid's rmse: 2206.7\n",
      "[27]\ttrain's rmse: 2080.76\tvalid's rmse: 2186.28\n",
      "[28]\ttrain's rmse: 2067.72\tvalid's rmse: 2173.96\n",
      "[29]\ttrain's rmse: 2052.51\tvalid's rmse: 2157.33\n",
      "[30]\ttrain's rmse: 2044.37\tvalid's rmse: 2150.73\n",
      "[31]\ttrain's rmse: 2036.54\tvalid's rmse: 2143.44\n",
      "[32]\ttrain's rmse: 2026.79\tvalid's rmse: 2134.56\n",
      "[33]\ttrain's rmse: 2013.8\tvalid's rmse: 2122.47\n",
      "[34]\ttrain's rmse: 2002.92\tvalid's rmse: 2113.1\n",
      "[35]\ttrain's rmse: 1997.5\tvalid's rmse: 2109.27\n",
      "[36]\ttrain's rmse: 1989.09\tvalid's rmse: 2101.86\n",
      "[37]\ttrain's rmse: 1977.93\tvalid's rmse: 2091.75\n",
      "[38]\ttrain's rmse: 1966.28\tvalid's rmse: 2081.15\n",
      "[39]\ttrain's rmse: 1955.95\tvalid's rmse: 2071.3\n",
      "[40]\ttrain's rmse: 1951.67\tvalid's rmse: 2067.99\n",
      "[41]\ttrain's rmse: 1935.49\tvalid's rmse: 2052.98\n",
      "[42]\ttrain's rmse: 1921.79\tvalid's rmse: 2040.6\n",
      "[43]\ttrain's rmse: 1908.31\tvalid's rmse: 2028.02\n",
      "[44]\ttrain's rmse: 1896.4\tvalid's rmse: 2017.49\n",
      "[45]\ttrain's rmse: 1892.95\tvalid's rmse: 2014.94\n",
      "[46]\ttrain's rmse: 1884.11\tvalid's rmse: 2006.67\n",
      "[47]\ttrain's rmse: 1875.6\tvalid's rmse: 1999.35\n",
      "[48]\ttrain's rmse: 1871.57\tvalid's rmse: 1997.94\n",
      "[49]\ttrain's rmse: 1860.37\tvalid's rmse: 1987.33\n",
      "[50]\ttrain's rmse: 1857.01\tvalid's rmse: 1984.8\n",
      "[51]\ttrain's rmse: 1848.37\tvalid's rmse: 1976.3\n",
      "[52]\ttrain's rmse: 1839.59\tvalid's rmse: 1967.25\n",
      "[53]\ttrain's rmse: 1827.43\tvalid's rmse: 1955.35\n",
      "[54]\ttrain's rmse: 1822.71\tvalid's rmse: 1950.84\n",
      "[55]\ttrain's rmse: 1815.12\tvalid's rmse: 1943.8\n",
      "[56]\ttrain's rmse: 1807.18\tvalid's rmse: 1936.81\n",
      "[57]\ttrain's rmse: 1801.47\tvalid's rmse: 1931.2\n",
      "[58]\ttrain's rmse: 1798.74\tvalid's rmse: 1929.38\n",
      "[59]\ttrain's rmse: 1790.73\tvalid's rmse: 1921.51\n",
      "[60]\ttrain's rmse: 1782.67\tvalid's rmse: 1913.93\n",
      "[61]\ttrain's rmse: 1777.74\tvalid's rmse: 1910.95\n",
      "[62]\ttrain's rmse: 1772.32\tvalid's rmse: 1906.1\n",
      "[63]\ttrain's rmse: 1769.79\tvalid's rmse: 1904.14\n",
      "[64]\ttrain's rmse: 1762.74\tvalid's rmse: 1897.3\n",
      "[65]\ttrain's rmse: 1755.81\tvalid's rmse: 1891.17\n",
      "[66]\ttrain's rmse: 1749.95\tvalid's rmse: 1885.37\n",
      "[67]\ttrain's rmse: 1745.71\tvalid's rmse: 1881.65\n",
      "[68]\ttrain's rmse: 1743.74\tvalid's rmse: 1880.82\n",
      "[69]\ttrain's rmse: 1738.67\tvalid's rmse: 1876.6\n",
      "[70]\ttrain's rmse: 1732.91\tvalid's rmse: 1871.12\n",
      "[71]\ttrain's rmse: 1727.88\tvalid's rmse: 1866.6\n",
      "[72]\ttrain's rmse: 1722.23\tvalid's rmse: 1861.35\n",
      "[73]\ttrain's rmse: 1713.59\tvalid's rmse: 1852.87\n",
      "[74]\ttrain's rmse: 1705.06\tvalid's rmse: 1844.21\n",
      "[75]\ttrain's rmse: 1700.34\tvalid's rmse: 1843.63\n",
      "[76]\ttrain's rmse: 1695.69\tvalid's rmse: 1839.22\n",
      "[77]\ttrain's rmse: 1692.93\tvalid's rmse: 1837.23\n",
      "[78]\ttrain's rmse: 1686.41\tvalid's rmse: 1830.81\n",
      "[79]\ttrain's rmse: 1679.94\tvalid's rmse: 1824.24\n",
      "[80]\ttrain's rmse: 1676.48\tvalid's rmse: 1821.27\n",
      "[81]\ttrain's rmse: 1670.05\tvalid's rmse: 1814.93\n",
      "[82]\ttrain's rmse: 1665.43\tvalid's rmse: 1811.24\n",
      "[83]\ttrain's rmse: 1659.92\tvalid's rmse: 1806.3\n",
      "[84]\ttrain's rmse: 1655.96\tvalid's rmse: 1802.08\n",
      "[85]\ttrain's rmse: 1652.01\tvalid's rmse: 1794.41\n",
      "[86]\ttrain's rmse: 1650.46\tvalid's rmse: 1792.42\n",
      "[87]\ttrain's rmse: 1646.54\tvalid's rmse: 1788.57\n",
      "[88]\ttrain's rmse: 1643.05\tvalid's rmse: 1784.1\n",
      "[89]\ttrain's rmse: 1636.61\tvalid's rmse: 1778.04\n",
      "[90]\ttrain's rmse: 1632.44\tvalid's rmse: 1774.15\n",
      "[91]\ttrain's rmse: 1626.23\tvalid's rmse: 1768.26\n",
      "[92]\ttrain's rmse: 1621.66\tvalid's rmse: 1764.13\n",
      "[93]\ttrain's rmse: 1617.55\tvalid's rmse: 1760.58\n",
      "[94]\ttrain's rmse: 1613.26\tvalid's rmse: 1757.16\n",
      "[95]\ttrain's rmse: 1609.49\tvalid's rmse: 1753.83\n",
      "[96]\ttrain's rmse: 1604.18\tvalid's rmse: 1748.53\n",
      "[97]\ttrain's rmse: 1600.82\tvalid's rmse: 1745.17\n",
      "[98]\ttrain's rmse: 1594.72\tvalid's rmse: 1739.86\n",
      "[99]\ttrain's rmse: 1592.05\tvalid's rmse: 1738.84\n",
      "[100]\ttrain's rmse: 1589.86\tvalid's rmse: 1737.57\n",
      "RMSPE RMSPE RMSPE RMSPE RMSPE RMSPE: 0.3085\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "modeldict = mpre2.load_models(TMP_DIR)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "load開始\n",
      "load終わりました\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "pred_dict"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{1: array([[ 6495.78620506],\n",
       "        [ 6407.08995631],\n",
       "        [ 8742.68250883],\n",
       "        ...,\n",
       "        [ 5550.3949349 ],\n",
       "        [17420.17054874],\n",
       "        [ 5428.42836637]]),\n",
       " 2: array([[ 6087.100284  ],\n",
       "        [ 6686.49205925],\n",
       "        [ 8529.82967159],\n",
       "        ...,\n",
       "        [ 5804.27020875],\n",
       "        [18805.87994394],\n",
       "        [ 5628.94142969]]),\n",
       " 3: array([[ 6127.47238877],\n",
       "        [ 7023.28959974],\n",
       "        [ 8956.93612206],\n",
       "        ...,\n",
       "        [ 6213.77563361],\n",
       "        [18508.17462156],\n",
       "        [ 5806.0774262 ]])}"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "pred_dict = mpre2.mk_pred_dict(modeldict,test_x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "予測リストが入った辞書作成開始\n",
      "予測リストが入った辞書作成終了\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "pred_wei_average = mpre2.wei_average(pred_dict,len(test_x))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "複数モデルを使用した重み付き平均予測を開始します\n",
      "重み付き平均pred_wei_averageがreturnされます\n",
      "重み付き平均pred_wei_averageがreturnされました\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "subpred = pd.DataFrame(pred_wei_average)\r\n",
    "# subpred.sort_values('Sales')\r\n",
    "\r\n",
    "sub = pd.concat([test['Id'],subpred],axis=1)\r\n",
    "sub.columns = ['Id','Sales']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "mpre2.mk_output(df=sub,NOW=NOW,PRACTICE=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('rake4': conda)"
  },
  "interpreter": {
   "hash": "dd5a840675b4b7a0124460e0160a18be5bf8441ea5223e9a03f358a511ddc22e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}